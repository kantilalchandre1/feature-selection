{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SelectKBest on load_iris--------\n",
      "(150, 4)\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "print('---------SelectKBest on load_iris--------')\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "print(X_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SelectPercentile on load_digits--------\n",
      "(1797, 64)\n",
      "(1797, 7)\n"
     ]
    }
   ],
   "source": [
    "print('---------SelectPercentile on load_digits--------')\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "X, y = load_digits(return_X_y=True)\n",
    "print(X.shape)\n",
    "\n",
    "X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n",
    "print(X_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------GenericUnivariateSelect--------\n",
      "(569, 30)\n",
      "(569, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('---------GenericUnivariateSelect--------')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, chi2\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "print(X.shape)\n",
    "\n",
    "transformer = GenericUnivariateSelect(chi2, 'k_best', param=20)\n",
    "X_new = transformer.fit_transform(X, y)\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimination\n",
    "\n",
    "Linear models penalized with the L1 norm have sparse solutions: many of their estimated coefficients are zero. \n",
    "\n",
    "When the goal is to reduce the dimensionality of the data to use with another classifier, they can be used along with feature_selection.SelectFromModel to select the non-zero\n",
    "coefficients. \n",
    "\n",
    "for this purpose are the linear_model.Lasso for regression, and of linear_model.LogisticRegression and svm.LinearSVC for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimination\n",
    "\n",
    "Tree-based estimators :can be used to compute feature importances, which in turn can be used to discard irrelevant features (when coupled with the sklearn.feature_selection.SelectFromModel meta-transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganapathi raju\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "clf.feature_importances_  \n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(X_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
